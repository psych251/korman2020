---
title: "Replication of Study 1 by Korman and Khemlani (2020, Cognition)"
author: "Joanna Korman (jkorman@mitre.com) and Sangeet Khemlani"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
  pdf_document:
    toc: yes
    toc_depth: '3'
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

Psychological essentialism holds that some concepts represent their categories as having an inner quality, an essence—the underlying property that causes observable features—that isn’t directly observable (e.g., Medin & Ortony 1989). Essentialized categories are represented as having a true nature which is assumed to be shared among category members and responsible for similarities among members of a category (Gelman and Ware, 2012).  

One central question raised by psychological essentialism is whether essences are represented in terms of placeholders or with specified contents. My view is that essences aren't always represented in terms of placeholders. Instead placeholders are typically elaborated. And when they are the content of an essentialized category is given by a kind of purpose or telos. 

A range of evidence suggests that generics are a central vehicle by which essentialist assumptions about some categories are transmitted (e.g., Rhodes, Leslie, Tworek, 2012; Gelman, Ware & Kleinberg, 2010).  But so far this work has focused on a traits, attitudes, or superficial properties, all of which are plausibly not viewed as tele. For instance, Gelman et al (2010) and Rhodes et al (2012) focus on generics such as “Zarpies have stripes”, “Zarpies are orange”, “Zarpies are scared of ladybugs” and “Zarpies hate ice cream”. Exposure to these over their non-generic counterparts (e.g., This zarpie hates ice cream) leads both children and adults to tend to essentialize the category (i.e., zarpies). My question is whether generics amplify essentialist inferences when candidate features are thought to be associated with a thing's purpose, as opposed to merely reflecting e.g., superficial properties and traits. 

Some recent work that serves as part of the backdrop for my own research on this issue comes from Korman and Khemlani (2020) who investigate what they call "teleological generics" which are generic generalizations that concern purposes or functions. They propose that people are more inclined to accept some teleological generics such as "cars are for driving" over others, such as "cars are for parking" when the feature or property bears a principled connection to the category.  One linguistic test of whether a property bears a principled connection to a category concerns whether one finds self-referential generalizations, e.g., Xs, by virtue of being Xs, are Y, acceptable.  So they predict that acceptance of teleological generics will be correlated with acceptance of self-referential generalizations.  In other words, people should be more inclined to accept "cars are for driving" than "cars are for parking" to the extent that they accept "cars, by virtue of being cars, are for driving" over "cars, by virtue of being cars, are for parking".  This is what is explored in their Experiment 1, which will be the focus of my replication.

In Experiment 1 of Korman and Khemlani (2020), they presented half of their participants with a number of different teleological generic statements--i.e., assertions of the form NPplural+VPpurposive, e.g., “cars” + “are for driving”--that varied in whether the noun concerned artifacts (e.g., chairs) or biological parts (e.g., eyes) and whether the verbs, experimental and control, yielded either acceptable generalizations (e.g., chairs are for sitting, eyes are for seeing) or false generalizations (e.g., chairs are for dusting, eyes are for blinking). The other half of participants received those same statements in the form of self-referential generalizations (e.g., chairs, in virtue of being chairs, are for sitting, chairs, in virtue of being chairs, are for dusting). Participants indicated whether they thought the statement was true or false on a 7pt Likert scale ranging from -3 (definitely false) to 3 (definitely true). Their study thus involved a mixed design with  Type(Teleological, Self-Referential) as a between-subjects factor and Statement(Experimental, Control) as a within-subjects factor. I don't anticipate any major challenges in implementing this replication.

The link to the repository is [here](https://github.com/psych251/korman2020) and the link to the paper is [here](https://github.com/psych251/korman2020/tree/master/original_paper)




##Methods

###Power Analysis

The effect size they report for whether experimental and control items differ, arguably their most important test, is Cliff's δ=0.99.  This converts to Cohen's d=4.66 (see below). Because this is an incredibly large effect size, the sample sizes to detect this effect at 80%, 90% and 95% are very small (see power analyses below). At 80% and 90% power, I would only need a sample of roughy four people to detect an effect of the size they report. At 95% I would only need six participants.

### Load Packages

```{r}

library("orddom") # computes ordinal statistics and effects sizes, inclduing conversions from Cliffs delta to Cohen's d
library("pwr") # for power analysis

```

### Power Analysis
```{r}

delta2cohd(.99) # Convert Cliffs delta to Cohen's d

pwr.t.test(n = 51, d = 4.66, type = "two.sample", alternative = "two.sided") # posthoc power to detect effect-size they report given the sample size they used


pwr.t.test(d = 4.66, power = 0.80, type="two.sample",alternative="two.sided") # 80% power

pwr.t.test(d = 4.66, power = 0.90, type="two.sample",alternative="two.sided") # 90% power

pwr.t.test(d = 4.66, power = 0.95, type="two.sample",alternative="two.sided") # 95% power



```



###Planned Sample

Korman and Khemlani (2020) note that: “The sample size for each study (n = 50) was projected by doubling the sample size from a reference study (Prasada et al., 2013, Experiment 2, which had n = 25). To verify that our sample size was reasonable, we conducted a post-hoc power analysis using the “pwr” package in R. Our goal was to obtain .95 power to detect a large correlation (r = .50) at a conservative the standard .05 alpha error probability”. In their Experiment 1, 51 participants completed the experiment. See “Sample Size Rationale” [here](https://osf.io/vzmdj). Since their effect size is so large (see above) and the sample size needed to detect it so small, I decided to sample 25 people.  This is half of their origial sample size but 4 times more than the roughly 6 paricipants needed to detect an effect of the size they report with 95% power.

###Materials

The materials consist in a total of 88 statements.  Forty-four involve teleological generics and half are experimental items while the other half are control items.  The other 44 statements involve self-referential generalizations with half of those being experimental items and the other half being control items. The full set of materials can be found [here](https://osf.io/m9hjr/).

###Procedure	

Following Korman and Khemlani (2020), participants will be drawn from Amazon Mechanical Turk and paid $1.25 for their participation. Participants will be randomly assigned to receive either the teleological generics or the self-referential generalization items. Experimental and control statements in both the teleological generic and self-referential generalization conditions will be randomly rotated.  For each statement, participants will register their responses by moving a slider displayed ranging from −3 (definitely false) to 3 (definitely true). After rating each statement, participants will fill out a brief demographic questionnaire, reporting their age, biological sex and whether they are a native English speaker.

###Analysis Plan

I will follow the authors analysis plan as seen [here]( https://osf.io/r79zk/). First I will begin by aggregating the data (using the aggregating function in R), creating an “Answer” column and saving this data frame.  Next, I will conduct five Wilcoxon signed rank tests. The first will test for a difference between experimental and control statements.  The second will test for a difference between teleological generics and self-referential generalizations. The third will test for an interaction between these two variables. And the fourth and fifth will test experimental vs. control items for teleological generics and self-referential generalizations in isolation. Lastly, I will test for whether there is a correlation between teleological generics and self-referential generalizations.

###Differences from Original Study

The methods, procedure and analysis plan closely follow that of the authors and so I anticipate any differences between the replication and original study to be fairly minimal.  But there will be one difference. The authors report that participants were “notified that they would be entered into a drawing to win a $10 bonus if they followed the task instructions. The bonus was subsequently paid to 10% of participants, chosen randomly”. To keep study costs down, participants will not be paid the bonus but instead will be paid, as the authors did, and they will only be paid $1.25 upon study completion.


### Methods Addendum (Post Data Collection)


#### Actual Sample
The final sample size was 24.  Though 25 people were recruited from Amazon Mechanical Turk and tested in Qualtrics, one response was not recorded.  MTurk showed that 25 people completed the task; Qualtrics shows that 25 people completed it.  But for some reason, one response didn't end up actually being recorded.  
  
Mean age in the final sample was 32.65 (range of 24 - 55) after removing an outlier (reported age of 532). Six participants (25%) indicated that they were female. All participants reported English as their native language.


#### Differences from pre-data collection methods plan
There were no differences from what was described in the original plan, at least concerning data collection.  But one issue was that, as mentioned above, one response did not record.  The other was that 4 participants didn't respond to all the items and this led to difficulties with the Wilcoxon test. Instead of removing NA's, I had to replace them all with 0's. I also did not, as described in "Analysis Plan" above, make use of the aggregate function since it didn't seem necessary in the end.  


##Results

### Experiment
The experiment can be found [here](https://stanforduniversity.qualtrics.com/jfe/form/SV_9yvQ3unW3RCchLL)

### Load packages 

```{r, message=F}
library("coin")   #from Korman and Khemlani for Wilcoxon tests
library("knitr")      # for knitting  
library("tidyverse")  # for everything else 
```


### Read in data

```{r}

# Pilot A 
df.pilotA.data = read.csv("../../korman2020/data/Replication_Pilot_A.csv")

df.pilotA.formatted = df.pilotA.data %>%
  #select only measurement variables
  select(t_e_chair_1:s_c_stomach_1) %>%  
  pivot_longer(cols=c(t_e_chair_1:s_c_stomach_1),
               names_to = "Measurement", 
               values_to = "Value",
               values_drop_na = TRUE) %>%
  separate(Measurement, c("Type", "Statement", "Item", "Extra"), "_") %>% 
  # remove "Extra" since not needed
  select(-c(Extra)) %>%
  #convert to factor and rename levels
  mutate(Type = factor(Type, labels = c("self-referential", "teleological")),
         Statement = factor(Statement, labels = c("control", "experimental")),
         Item = factor (Item))

#Pilot B
df.pilotB.data = read.csv("../../korman2020/data/Replication_Pilot_B.csv")

df.pilotB.formatted = df.pilotB.data %>%
  #select only the four participants in Pilot B
  slice(8:11) %>%
  #select only measurement variables
  select(t_e_chair_1:s_c_stomach_1) %>%  
  pivot_longer(cols=c(t_e_chair_1:s_c_stomach_1),
               names_to = "Measurement", 
               values_to = "Value",
               values_drop_na = TRUE) %>%
  separate(Measurement, c("Type", "Statement", "Item", "Extra"), "_") %>% 
  # remove "Extra" since not needed
  select(-c(Extra)) %>%
  #convert to factor and rename levels
  mutate(Type = factor(Type, labels = c("self-referential", "teleological")),
         Statement = factor(Statement, labels = c("control", "experimental")),
         Item = factor (Item)) 
 
         
# Final Data for Replication
df.final.data = read.csv("../../korman2020/data/Replication_Final.csv")

#Dataset removing NA's
df.final.formatted.long = df.final.data %>%
  #select only the twenty-five participants in the final replication
  slice(12:37) %>%
  #select only measurement variables
  select(t_e_chair_1:s_c_stomach_1) %>%
  mutate(Participant = 1:n()) %>% 
  pivot_longer(cols=c(t_e_chair_1:s_c_stomach_1),
               names_to = "Measurement",
               values_to = "Value") %>%
  separate(Measurement, c("Type", "Statement", "Item", "Extra"), "_") %>%
  # remove "Extra" since not needed
  select(-c(Extra)) %>%
  #convert to factor and rename levels
  mutate(Type = factor(Type, labels = c("self-referential", "teleological")),
         Statement = factor(Statement, labels = c("control", "experimental")),
         Item = factor (Item)) %>% 
  relocate(Participant) %>% 
  na.omit() %>% 
  # fix typos 
  mutate(Item = str_replace(Item, "fortk", "fork"),
         Item = str_replace(Item, "thraot", "throat")) %>%
  # fix mislabeled items 
  mutate(Item_duplicate = duplicated(.[,1:4]),
         Item = ifelse(Item_duplicate & Item == "muscle", "ear", Item),
         Item = ifelse(Item_duplicate & Item == "chair", "car", Item)) %>% 
  select(-Item_duplicate) 


#Dataset for replacing NA's with 0's (for the Wilcoxon Tests)
df.final.formatted.long.test = df.final.data %>%
  #select only the twenty-five participants in the final replication
  slice(12:37) %>%
  #select only measurement variables
  select(t_e_chair_1:s_c_stomach_1) %>%
  mutate(Participant = 1:n()) %>% 
  pivot_longer(cols=c(t_e_chair_1:s_c_stomach_1),
               names_to = "Measurement",
               values_to = "Value") %>%
  separate(Measurement, c("Type", "Statement", "Item", "Extra"), "_") %>%
  # remove "Extra" since not needed
  select(-c(Extra)) %>%
  #convert to factor and rename levels
  mutate(Type = factor(Type, labels = c("self-referential", "teleological")),
         Statement = factor(Statement, labels = c("control", "experimental")),
         Item = factor (Item)) %>% 
  relocate(Participant) %>% 
  # fix typos 
  mutate(Item = str_replace(Item, "fortk", "fork"),
         Item = str_replace(Item, "thraot", "throat")) %>%
  # fix mislabeled items 
  mutate(Item_duplicate = duplicated(.[,1:4]),
         Item = ifelse(Item_duplicate & Item == "muscle", "ear", Item),
         Item = ifelse(Item_duplicate & Item == "chair", "car", Item)) %>% 
  select(-Item_duplicate) 

#Replace NA's with 0's
df.final.formatted.long.test[is.na(df.final.formatted.long.test)] = 0



#Final Data Demographics
df.final.demo = df.final.data %>%
  #select only the twenty-five participants in the final replication
  slice(12:37) %>%
  #select only demographic variables
  select(age:native)

head(df.final.formatted.long)
         
```

### Demographics
```{r}
#Final sample demographics
age = df.final.demo %>%
  summarise(mean_age = mean(age), age_range = range(age))

#remove outlier(person who reported age of 532)
age_adjusted = df.final.demo %>%
  filter(!(age == "532")) %>%
  summarise(mean_age = mean(age), age_range = range(age))

native_english = df.final.demo %>% 
  count(native, sort = TRUE)

gender = df.final.demo %>%
  count(sex, sort = TRUE)


age
age_adjusted
native_english
gender
```

### Descriptives

```{r}
df.pilotA.means = df.pilotA.formatted %>%
  group_by(Type, Statement) %>%
  summarise(MeanRating = mean((Value), na.rm = TRUE), SD =sd((Value), na.rm = TRUE)) %>%
  ungroup()

df.pilotA.means

df.pilotB.means = df.pilotB.formatted %>%
  group_by(Type, Statement) %>%
  summarise(MeanRating = mean((Value), na.rm = TRUE), SD =sd((Value), na.rm = TRUE)) %>%
  ungroup()

df.pilotB.means

df.final.means = df.final.formatted.long %>%
  group_by(Type, Statement) %>%
  summarise(MeanRating = mean((Value), na.rm = TRUE), SD =sd((Value), na.rm = TRUE)) %>%
  ungroup()

df.final.means
  

```
### Plot

```{r fig.height=14, fig.width=10}

library("gridExtra")


pilotA = ggplot(data = df.pilotA.formatted,
       mapping = aes(x = Statement,
                     y = Value,
                     group = Type,
                     fill = Type)) + 
  stat_summary(fun = "mean", 
               geom = "bar", 
               position = position_dodge(width = 0.9)) +
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "linerange",
               position = position_dodge(width = 0.9)) +
  scale_fill_brewer(palette = "Set1") + 
  scale_y_continuous(breaks = seq(from = -3, to = 3, by = 1)) +
  expand_limits(y = c(-3, 3)) + 
  labs(y = "Mean Rating",
    title= "Pilot A")


pilotB = ggplot(data = df.pilotB.formatted,
       mapping = aes(x = Statement,
                     y = Value,
                     group = Type,
                     fill = Type)) + 
  stat_summary(fun = "mean", 
               geom = "bar", 
               position = position_dodge(width = 0.9)) +
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "linerange",
               position = position_dodge(width = 0.9)) +
  scale_fill_brewer(palette = "Set1") + 
  scale_y_continuous(breaks = seq(from = -3, to = 3, by = 1)) +
  expand_limits(y = c(-3, 3)) + 
  labs(y = "Mean Rating",
    title= "Pilot B")

final = ggplot(data = df.final.formatted.long,
       mapping = aes(x = Statement,
                     y = Value,
                     group = Type,
                     fill = Type)) +
  stat_summary(fun = "mean",
               geom = "bar",
               position = position_dodge(width = 0.9)) +
  stat_summary(fun.data = "mean_cl_boot",
               geom = "linerange",
               position = position_dodge(width = 0.9)) +
  scale_fill_brewer(palette = "Set1") +
  scale_y_continuous(breaks = seq(from = -3, to = 3, by = 1)) +
  expand_limits(y = c(-3, 3)) +
  labs(y = "Mean Rating",
    title= "Replication")


# original paper data for graph
original.df = tibble(Type = rep(c("self-referential", "teleological"), each = 2),
                 Statement = rep(c("experimental", "control"), 2)) %>% 
  mutate(prediction = c(2.48, -.91, 2.50, -.67),
         sd = c(1.01, 1.97, 1.0, 1.98),
         ci = c(.28, .55, .28, .55))
         

original.plot = ggplot(data = original.df,
       mapping = aes(x = Statement,
                     y = prediction,
                     group = Type,
                     fill = Type)) + 
  geom_bar(color = "black",
           stat = "identity",
           position = position_dodge(width = .9)) +
   geom_errorbar(aes(ymin=prediction-ci, 
                    ymax=prediction+ci), 
                    width=0,
                    position = position_dodge(width = .9)) +
  scale_fill_brewer(palette = "Set1") + 
  scale_y_continuous(breaks = seq(from = -3, to = 3, by = 1)) +
  expand_limits(y = c(-3, 3)) + 
  labs(y = "Mean Rating",
       title= "Original Results")



grid.arrange(original.plot, pilotA, pilotB, final)

ggsave("replication.png", grid.arrange(original.plot, pilotA, pilotB, final))

```

### Confirmatory analysis (following Korman and Khemlani analyses)

### 1. Wilcoxon test: experimental vs. control

```{r}

# Pilot A
wilcoxsign_test(df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "control"] ~
                df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "experimental"])

# Pilot B
wilcoxsign_test(df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "control"] ~
                df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "experimental"])

# Final
wilcoxsign_test(df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "control"] ~
                df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "experimental"])


```
### 2. Wilcoxon test: teleological vs. self-referential

```{r}

# Pilot A
wilcoxsign_test(df.pilotA.formatted$Value[df.pilotA.formatted$Type == "teleological"] ~
                df.pilotA.formatted$Value[df.pilotA.formatted$Type == "self-referential"])

# Pilot B
wilcoxsign_test(df.pilotB.formatted$Value[df.pilotB.formatted$Type == "teleological"] ~
                df.pilotB.formatted$Value[df.pilotB.formatted$Type == "self-referential"])

# Final
wilcoxsign_test(df.final.formatted.long.test$Value[df.final.formatted.long.test$Type == "teleological"] ~
                df.final.formatted.long.test$Value[df.final.formatted.long.test$Type == "self-referential"])


```
### 3. Wilcoxon test: interaction between Type and Statement
```{r}

#Pilot A
Control <- df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "control" & df.pilotA.formatted$Type == "teleological"] - 
  df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "control" & df.pilotA.formatted$Type == "self-referential"]

Experimental <- df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "experimental" & df.pilotA.formatted$Type == "teleological"] - 
  df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "experimental" & df.pilotA.formatted$Type == "self-referential"]

wilcoxsign_test(Control ~ Experimental)

#Pilot B
Control <- df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "control" & df.pilotB.formatted$Type == "teleological"] - 
  df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "control" & df.pilotB.formatted$Type == "self-referential"]

Experimental <- df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "experimental" & df.pilotB.formatted$Type == "teleological"] - 
  df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "experimental" & df.pilotB.formatted$Type == "self-referential"]

wilcoxsign_test(Control ~ Experimental)

#Final
Control <- df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "control" & df.final.formatted.long.test$Type == "teleological"] -
  df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "control" & df.final.formatted.long.test$Type == "self-referential"]

Experimental <- df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "experimental" & df.final.formatted.long.test$Type == "teleological"] -
  df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "experimental" & df.final.formatted.long.test$Type == "self-referential"]

wilcoxsign_test(Control ~ Experimental)

```
### 4.  Wilcoxon tests for planned comparisons
```{r}

#Pilot A
#test of experimental vs. control within teleological
wilcoxsign_test(df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "experimental" &
                               df.pilotA.formatted$Type == "teleological"] ~
                df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "control" &
                               df.pilotA.formatted$Type == "teleological"])

#test of experimental vs. control within self-referential
wilcoxsign_test(df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "experimental" &
                               df.pilotA.formatted$Type == "self-referential"] ~
                df.pilotA.formatted$Value[df.pilotA.formatted$Statement == "control" &
                               df.pilotA.formatted$Type == "self-referential"])

#Pilot B
#test of experimental vs. control within teleological
wilcoxsign_test(df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "experimental" &
                               df.pilotB.formatted$Type == "teleological"] ~
                df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "control" &
                               df.pilotB.formatted$Type == "teleological"])

#test of experimental vs. control within self-referential
wilcoxsign_test(df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "experimental" &
                               df.pilotB.formatted$Type == "self-referential"] ~
                df.pilotB.formatted$Value[df.pilotB.formatted$Statement == "control" &
                               df.pilotB.formatted$Type == "self-referential"])

#Final
#test of experimental vs. control within teleological
wilcoxsign_test(df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "experimental" &
                               df.final.formatted.long.test$Type == "teleological"] ~
                df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "control" &
                               df.final.formatted.long.test$Type == "teleological"])

#test of experimental vs. control within self-referential
wilcoxsign_test(df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "experimental" &
                               df.final.formatted.long.test$Type == "self-referential"] ~
                df.final.formatted.long.test$Value[df.final.formatted.long.test$Statement == "control" &
                               df.final.formatted.long.test$Type == "self-referential"])
```
### 5. Correlation between teleological and self-referential
```{r}

#Pilot A
cor.test(df.pilotA.formatted$Value[df.pilotA.formatted$Type == "teleological"], df.pilotA.formatted$Value[df.pilotA.formatted$Type == "self-referential"], 
         method = "pearson")

#Pilot B
cor.test(df.pilotB.formatted$Value[df.pilotB.formatted$Type == "teleological"], df.pilotB.formatted$Value[df.pilotB.formatted$Type == "self-referential"], 
         method = "pearson")

#Final
cor.test(df.final.formatted.long.test$Value[df.final.formatted.long.test$Type == "teleological"], df.final.formatted.long.test$Value[df.final.formatted.long.test$Type == "self-referential"],
         method = "pearson")
```


###Exploratory analyses

No I didn't conduct any exploratory analyses.  

## Discussion

### Summary of Replication Attempt

I was able to successfully replicate the original experiment 1 results from Korman and Khemladi (2020).  In fact, I replicated their findings at each step of the replication process, from pilots A and B to final data collection.  The main finding is that there is a difference in the evaluation of experimental and control statements and no difference in the overall evaluation of teleological and self-referential statements.

### Commentary

The experiment successfully replicated.  I think there are at least two things that made this successful.  One was that the original effect was very large.  The other was that the authors had incredible documentation that made it very easy to follow their procedure step-by-step.  This last point bears emphasizing.  Doing a replication for a project that has little to no documentation would take a real herculean effort.  Having open, accessible, easily understandable and implementable materials massively reduces the kinds of typical frustrations that accompany a replication. I deeply appreciate the fact that the authors made their material easily accessible, understandable and straightforwardly implementable.  Their work has served as an excellent model for open and assessable science.  I plan to follow this in all my research moving forward.

I also learned a couple of other valuable lessons about the experimental process.  One is that it is very important to make sure variables are all labeled appropriately and typo free before collecting data.  This will save time and headaches since you will spend less on data wrangling.  I’m very grateful to Tobi Gerstenberg for his assistance with helping me identify these issue and wrangle accordingly.  The second thing is that some decisions need to be made about how to handle missing data.  For instance, if a variable consists of responses to several items, failure to respond to one item can have an affect on data analysis.  In my case this posed an issue for carrying out the Wilcoxon tests that the authors conducted.  Do you drop all of the data associated with that participant or replace the missing value for the relevant items with a 0?  In my case, I went with the latter.  But I could have went with the former.  This is decision point that should be dealt with in advance.  In my own case, I didn’t anticipate it.  So while unexpected issues might arise, after grappling with them, they will then hopefully serve as part of the experimental planning and preregistration process. 

